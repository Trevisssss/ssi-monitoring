# ü§ñ Monitor de SSI do LinkedIn

### üìÑ Descri√ß√£o

Este projeto √© uma solu√ß√£o completa de ETL (Extra√ß√£o, Transforma√ß√£o e Carga) e Data Analytics desenvolvida em Python para automatizar a coleta da pontua√ß√£o do Social Selling Index (SSI) do LinkedIn. O objetivo √© extrair os dados diariamente, armazen√°-los e visualizar a evolu√ß√£o das m√©tricas ao longo do tempo atrav√©s de um dashboard interativo.

O projeto foi constru√≠do de forma modular, separando as responsabilidades de autentica√ß√£o, extra√ß√£o de dados (scraping), orquestra√ß√£o e visualiza√ß√£o.

### üõ†Ô∏è Tecnologias Utilizadas

- Linguagem: `Python 3.12`

- Automa√ß√£o Web (Autentica√ß√£o e Scraping): `Playwright`

- Manipula√ß√£o de Dados: `Pandas`

- Visualiza√ß√µes e Dashboard: `Matplotlib & Seaborn & Streamlit`


### üìÇ Estrutura do Projeto

O projeto √© dividido em m√≥dulos de forma que seja mais f√°cil identificar erros e implementar melhorias no c√≥digo em partes espec√≠ficas.

- **auth.py:** Respons√°vel por criar e salvar um estado de sess√£o autenticada, evitando a necessidade de fazer login a cada execu√ß√£o.

- **extraction_linkedin.py:** √â respons√°vel pelo web scraping. Usa a sess√£o salva para navegar at√© a p√°gina do SSI e extrair as cinco principais m√©tricas.

- **orquestrador.py:** Como forma de centralizar todas as a√ß√µes em um √∫nico local, o script orquestrador.py atua como o orquestrador do processo todo. Ele verifica se uma sess√£o de autentica√ß√£o existe; se n√£o, executa apenas o ETL, para coletar e salvar os dados do dia no arquivo `CSV`.

- **dashboard.py:** Utilizando o Streamlit em conjunto com pandas, matplotlib e seaborn, criei as visualiza√ß√µes necess√°rias para acompanhar a evolu√ß√£o dos indicadores do LinkedIn, que nativamente n√£o possui esse acompanhamento hist√≥rico.

### üéØ Desafios Superados

Durante o desenvolvimento, enfrentamos alguns desafios t√©cnicos que s√£o comuns em projetos de automa√ß√£o web e que serviram como grandes aprendizados:

‚ö†Ô∏è **Arquitetura:** Um dos desafios era qual a arquitetura a ser escolhida, pois at√© ent√£o s√≥ havia a ideia de que resolveria um 'problema'.
Cheguei a cogitar Power BI e Looker Studio pela facilidade de criar as visualiza√ß√µes e tamb√©m compartilhamento, mas como o projeto n√£o exige que haja um compartilhamento mais robusto e seguro, preferi simplificar em um ambiente unificado, al√©m de praticar conceitos mais novos.

üí°**Solu√ß√£o:** Optei por uma stack h√≠brida, onde o ETL √© feito em Python, automatizando a extra√ß√£o no site, e depois armazenando em um banco Postgres na nuvem (supabase). Anteriormente o dashboard foi feito com Streamlit, mas dada a minha experi√™ncia maior com Power BI e outras funcionalidades extras, migrei pra ele.


‚ö†Ô∏è**Login:** O LinkedIn n√£o possui uma API p√∫blica para o SSI e utiliza mecanismos avan√ßados para detectar e bloquear automa√ß√£o. A tentativa inicial de fazer login a cada execu√ß√£o falhou devido a CAPTCHAs e p√°ginas em branco.

üí°**Solu√ß√£o:** Implementei uma estrat√©gia de 'persist√™ncia' de sess√£o. A biblioteca `playwright` possibilita o salvamento de cookies, tokens e outros elementos que podem ser reaproveitados para que o login seja feito uma vez s√≥ manualmente, e os seguintes ocorram automaticamente. Isso permite uma maior simplifica√ß√£o na solu√ß√£o, ainda que n√£o idealmente ocorra de forma din√¢mica e autom√°tica.

> Nota: O projeto foi conclu√≠do em menos de 2 dias, e s√≥ foi poss√≠vel pela simplifica√ß√£o das ideias comentadas, como a quest√£o do login e da arquitetura escolhida. Mas a ideia √© deixar o projeto mais robusto enquanto estudo os conceitos da pr√≥xima sess√£o ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è:

### üöÄ Pr√≥ximos Passos

O projeto est√° funcional, mas h√° tr√™s melhorias principais planejadas para torn√°-lo uma solu√ß√£o de n√≠vel profissional:

**Migra√ß√£o para Banco de Dados na Nuvem: (Conclu√≠do)**

Anteriormente, os dados eram salvos em um arquivo CSV local. Com o objetivo de deixar este projeto o mais pr√≥ximo de um _case_ real poss√≠vel, o pr√≥ximo passo foi substituir o CSV por um banco de dados na nuvem, a ideia inicial era usar o bigquery, por√©m por limita√ß√µes do plano free tive que ir para outra solu√ß√£o, e a encontrada foi o `Supabase`, que utiliza um banco Postegres por tr√°s.

**Melhorar o Processo de Autentica√ß√£o:**

A abordagem de sess√£o persistente usando a biblioteca `playwright` √© eficaz, mas a sess√£o pode expirar ou ser invalidada, exigindo a recria√ß√£o manual do arquivo de autentica√ß√£o. Um pr√≥ximo passo importante √© desenvolver uma rotina de login totalmente automatizada, capaz de detectar a necessidade de uma nova autentica√ß√£o e realiz√°-la sem interven√ß√£o.


**Automa√ß√£o Aprimorada:**

A execu√ß√£o do script ainda √© manual. O objetivo final √© automatizar a execu√ß√£o di√°ria do script orquestrador.py sem depender de um computador local. A principal tecnologia a ser explorada para isso √© o `GitHub Actions`, criando um workflow agendado (cron) que rodar√° o processo de ETL diretamente do reposit√≥rio.

Existem outras formas de implementar essa solu√ß√£o, mas exigem um maior investimento de tempo e conhecimento, e o GitHub Actions parece ser a mais simples para este projeto.


