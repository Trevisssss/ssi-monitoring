# ü§ñ Monitor de SSI do LinkedIn

### üìÑ Descri√ß√£o

Este projeto √© uma solu√ß√£o completa de ETL (Extra√ß√£o, Transforma√ß√£o e Carga) e Data Analytics desenvolvida em Python para automatizar a coleta da pontua√ß√£o do Social Selling Index (SSI) do LinkedIn. O objetivo √© extrair os dados diariamente, armazen√°-los e visualizar a evolu√ß√£o das m√©tricas ao longo do tempo atrav√©s de um dashboard interativo.

O projeto foi constru√≠do de forma modular, separando as responsabilidades de autentica√ß√£o, extra√ß√£o de dados (scraping), orquestra√ß√£o e visualiza√ß√£o.

### üõ†Ô∏è Tecnologias Utilizadas

- Linguagem: `Python 3.12`

- Automa√ß√£o Web (Autentica√ß√£o e Scraping): `Playwright`

- Manipula√ß√£o de Dados: `Pandas`

- Visualiza√ß√µes e Dashboard: `Matplotlib & Seaborn & Streamlit`


### üìÇ Estrutura do Projeto

O projeto √© dividido em m√≥dulos de forma com que seja mais f√°cil identificar erros e implementar melhorias no c√≥digo em partes espec√≠ficas.

- **auth.py:** Respons√°vel por criar e salvar um estado de sess√£o autenticada, evitando a necessidade de fazer login a cada execu√ß√£o.

- **extraction_linkedin.py:** √â respons√°vel pelo web scraping. Usa a sess√£o salva para navegar at√© a p√°gina do SSI e extrair as cinco principais m√©tricas.

- **orquestrador.py:** Como forma de centralizar todas as a√ß√µes em um √∫nico local, o script orquestrador.py atua como o orquestrador do processo todo. Ele verifica se uma sess√£o de autentica√ß√£o existe; se n√£o, executa apenas o ETL, para coletar e salvar os dados do dia no arquivo `CSV`.

- **dashboard.py:** Utilizando o Streamlit em conjunto com pandas, matplotlib e seaborn, criei as visualiza√ß√µes necess√°rias para acompanhar a evolu√ß√£o dos indicadores do LinkedIn, que nativamente n√£o possui esse acompanhamento hist√≥rico.

### üéØ Desafios Superados

Durante o desenvolvimento, enfrentamos alguns desafios t√©cnicos que s√£o comuns em projetos de automa√ß√£o web e que serviram como grandes aprendizados:

‚ö†Ô∏è **Arquitetura da Solu√ß√£o:** Um dos desafios era qual a arquitetura a ser escolhida, pois at√© ent√£o s√≥ havia a ideia que resolveria um 'problema'.
Cheguei a cogitar Power BI e Looker Studio pela facilidade de criar as visualiza√ß√µes e tamb√©m compartilhamento, mas como o projeto n√£o exige que haja um compartilhamento mais robusto e seguro, preferi simplificar em um ambiente unificado, al√©m de praticar conceitos mais novos.

üí°**Solu√ß√£o:** Optei por uma stack 100% Python, pois a linguagem normamente √© a refer√™ncia quando se trata de web scraping em projetos de dados. Com bibliotecas especializadas tanto para a extra√ß√£o (como Playwright) quanto para a visualiza√ß√£o (como Streamlit e Seaborn), permitiu manter todo o ciclo de vida do projeto em um ambiente √∫nico. 


‚ö†Ô∏è**Login:** O LinkedIn n√£o possui uma API p√∫blica para o SSI e utiliza mecanismos avan√ßados para detectar e bloquear automa√ß√£o. A tentativa inicial de fazer login a cada execu√ß√£o falhou devido a CAPTCHAs e p√°ginas em branco.

üí°**Solu√ß√£o:** Implementei uma estrat√©gia de 'persist√™ncia' de sess√£o. A biblioteca `playwright` possibilita o salvamento de cookies, tokens e outros elementos que podem ser reaproveitados pra que o login seja feito uma vez s√≥ manualmente, e os seguintes ocorram automaticamente. Isso permite uma maior simplifica√ß√£o na solu√ß√£o, ainda que n√£o idealmente ocorra de forma din√¢mica e autom√°tica.

> Nota: O projeto foi conclu√≠do em menos de 2 dias, e s√≥ foi poss√≠vel pela simplifica√ß√£o das ideias comentadas, como a quest√£o do login, e arquitetura escolhida. Mas a ideia √© deixar o projeto mais robusto enquanto estudo os conceitos da pr√≥xima sess√£o ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è:

### üöÄ Pr√≥ximos Passos

O projeto est√° funcional, mas h√° tr√™s melhorias principais planejadas para torn√°-lo uma solu√ß√£o de n√≠vel profissional:

**Melhorar o Processo de Autentica√ß√£o:**

A abordagem de sess√£o persistente usando a biblioteca `playwright` √© eficaz, mas a sess√£o pode expirar ou ser invalidada, exigindo a recria√ß√£o manual do arquivo de autentica√ß√£o. Um pr√≥ximo passo importante √© desenvolver uma rotina de login totalmente automatizada, capaz de detectar a necessidade de uma nova autentica√ß√£o e realiz√°-la sem interven√ß√£o humana.


**Migra√ß√£o para Banco de Dados na Nuvem:**

Atualmente, os dados s√£o salvos em um arquivo CSV local. Com o objetivo de deixar este projeto o mais pr√≥ximo de um case real poss√≠veo, o pr√≥ximo passo √© substituir o CSV por um banco de dados na nuvem, como Google BigQuery, Supabase (PostgreSQL) ou Neon. Isso trar√° mais escalabilidade, seguran√ßa e facilitar√° a conex√£o com outras ferramentas de BI.

**Automa√ß√£o Aprimorada:**

A execu√ß√£o do script ainda √© manual. O objetivo final √© automatizar a execu√ß√£o di√°ria do script orquestrador.py sem depender de um computador local. A principal tecnologia a ser explorada para isso √© o `GitHub Actions`, criando um workflow agendado (cron) que rodar√° o processo de ETL diretamente do reposit√≥rio.

Existem outras formas de implementar essa solu√ß√£o, mas exigem um maior investimento de tempo e conhecimento, e o GitHub Actions parece ser a mais simples pra este projeto.


